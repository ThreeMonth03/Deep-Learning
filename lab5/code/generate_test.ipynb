{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696c30d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  1\n",
      "Namespace(lr=0.0005, beta1=0.9, batch_size=12, log_dir='./logs/fp/rnn_size=256-predictor-posterior-rnn_layers=2-1-n_past=2-n_future=10-lr=0.0005-g_dim=128-z_dim=64-last_frame_skip=False-beta=0.0001000/continued', model_dir='./logs/fp/rnn_size=256-predictor-posterior-rnn_layers=2-1-n_past=2-n_future=10-lr=0.0005-g_dim=128-z_dim=64-last_frame_skip=False-beta=0.0001000', data_root='../processed_data', optimizer='adam', niter=300, epoch_size=600, tfr=0.0, tfr_start_decay_epoch=150, tfr_decay_step=0.01, tfr_lower_bound=0.0, kl_anneal_cyclical=True, kl_anneal_ratio=2, kl_anneal_cycle=4, seed=1, n_past=2, n_future=10, n_eval=30, rnn_size=256, posterior_rnn_layers=1, predictor_rnn_layers=2, z_dim=64, g_dim=128, beta=0.0001, num_workers=8, last_frame_skip=False, cuda=True)\n",
      "ave_psnr = 26.422777870572666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import bair_robot_pushing_dataset\n",
    "from models.lstm import gaussian_lstm, lstm\n",
    "from models.vgg_64 import vgg_decoder, vgg_encoder\n",
    "from utils import init_weights, kl_criterion, plot_pred, plot_rec, finn_eval_seq, pred\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--lr', default=0.002, type=float, help='learning rate')\n",
    "    parser.add_argument('--beta1', default=0.9, type=float, help='momentum term for adam')\n",
    "    parser.add_argument('--batch_size', default=12, type=int, help='batch size')\n",
    "    parser.add_argument('--log_dir', default='./logs/fp', help='base directory to save logs')\n",
    "    parser.add_argument('--model_dir', default='./logs/fp/rnn_size=256-predictor-posterior-rnn_layers=2-1-n_past=2-n_future=10-lr=0.0005-g_dim=128-z_dim=64-last_frame_skip=False-beta=0.0001000', help='base directory to save logs')\n",
    "    parser.add_argument('--data_root', default='../processed_data', help='root directory for data')\n",
    "    parser.add_argument('--optimizer', default='adam', help='optimizer to train with')\n",
    "    parser.add_argument('--niter', type=int, default=300, help='number of epochs to train for')\n",
    "    parser.add_argument('--epoch_size', type=int, default=600, help='epoch size')\n",
    "    parser.add_argument('--tfr', type=float, default=1.0, help='teacher forcing ratio (0 ~ 1)')\n",
    "    parser.add_argument('--tfr_start_decay_epoch', type=int, default=150, help='The epoch that teacher forcing ratio become decreasing')\n",
    "    parser.add_argument('--tfr_decay_step', type=float, default=0.01, help='The decay step size of teacher forcing ratio (0 ~ 1)')\n",
    "    parser.add_argument('--tfr_lower_bound', type=float, default=0.0, help='The lower bound of teacher forcing ratio for scheduling teacher forcing ratio (0 ~ 1)')\n",
    "    parser.add_argument('--kl_anneal_cyclical', default=False, action='store_true', help='use cyclical mode')\n",
    "    parser.add_argument('--kl_anneal_ratio', type=float, default=2, help='The decay ratio of kl annealing')\n",
    "    parser.add_argument('--kl_anneal_cycle', type=int, default=4, help='The number of cycle for kl annealing (if use cyclical mode)')\n",
    "    parser.add_argument('--seed', default=1, type=int, help='manual seed')\n",
    "    parser.add_argument('--n_past', type=int, default=2, help='number of frames to condition on')\n",
    "    parser.add_argument('--n_future', type=int, default=10, help='number of frames to predict')\n",
    "    parser.add_argument('--n_eval', type=int, default=30, help='number of frames to predict at eval time')\n",
    "    parser.add_argument('--rnn_size', type=int, default=256, help='dimensionality of hidden layer')\n",
    "    parser.add_argument('--posterior_rnn_layers', type=int, default=1, help='number of layers')\n",
    "    parser.add_argument('--predictor_rnn_layers', type=int, default=2, help='number of layers')\n",
    "    parser.add_argument('--z_dim', type=int, default=64, help='dimensionality of z_t')\n",
    "    parser.add_argument('--g_dim', type=int, default=128, help='dimensionality of encoder output vector and decoder input vector')\n",
    "    parser.add_argument('--beta', type=float, default=0.0001, help='weighting on KL to prior')\n",
    "    parser.add_argument('--num_workers', type=int, default=8, help='number of data loading threads')\n",
    "    parser.add_argument('--last_frame_skip', action='store_true', help='if true, skip connections go between frame t and frame t+t rather than last ground truth frame')\n",
    "    parser.add_argument('--cuda', default=True, action='store_true')  \n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    if args.cuda:\n",
    "        assert torch.cuda.is_available(), 'CUDA is not available.'\n",
    "        device = 'cuda:3'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    \n",
    "    assert args.n_past + args.n_future <= 30 and args.n_eval <= 30\n",
    "    assert 0 <= args.tfr and args.tfr <= 1\n",
    "    assert 0 <= args.tfr_start_decay_epoch \n",
    "    assert 0 <= args.tfr_decay_step and args.tfr_decay_step <= 1\n",
    "    assert args.model_dir != ''\n",
    "\n",
    "    if args.model_dir != '':\n",
    "        # load model and continue training from checkpoint\n",
    "        saved_model = torch.load('%s/model.pth' % args.model_dir)\n",
    "        optimizer = args.optimizer\n",
    "        model_dir = args.model_dir\n",
    "        niter = args.niter\n",
    "        args = saved_model['args']\n",
    "        args.optimizer = optimizer\n",
    "        args.model_dir = model_dir\n",
    "        args.log_dir = '%s/continued' % args.log_dir\n",
    "        start_epoch = saved_model['last_epoch']\n",
    "        \n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    os.makedirs('%s/gen/' % args.log_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Random Seed: \", args.seed)\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    print(args)\n",
    "\n",
    "    frame_predictor = saved_model['frame_predictor']\n",
    "    posterior = saved_model['posterior']\n",
    "    decoder = saved_model['decoder']\n",
    "    encoder = saved_model['encoder']\n",
    "\n",
    "    frame_predictor.to(device)\n",
    "    posterior.to(device)\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    # --------- load a dataset ------------------------------------\n",
    "    test_data = bair_robot_pushing_dataset(args, 'test')\n",
    "    test_loader = DataLoader(test_data,\n",
    "                            num_workers=args.num_workers,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=True,\n",
    "                            pin_memory=True)\n",
    "\n",
    "    test_iterator = iter(test_loader)\n",
    "\n",
    "    modules = {\n",
    "        'frame_predictor': frame_predictor,\n",
    "        'posterior': posterior,\n",
    "        'encoder': encoder,\n",
    "        'decoder': decoder,\n",
    "    }\n",
    "\n",
    "    frame_predictor.eval()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    posterior.eval()\n",
    "\n",
    "    psnr_list = []\n",
    "    for _ in range(len(test_data) // args.batch_size):\n",
    "        try:\n",
    "            test_seq, test_cond = next(test_iterator)\n",
    "        except StopIteration:\n",
    "            test_iterator = iter(testloader)\n",
    "            test_seq, test_cond = next(test_iterator)\n",
    "\n",
    "        test_seq = test_seq.transpose(0, 1).to(device)\n",
    "        test_cond = test_cond.transpose(0, 1).to(device)\n",
    "        pred_seq = pred(test_seq, test_cond, modules, args, device)\n",
    "        _, _, psnr = finn_eval_seq(test_seq[args.n_past:], pred_seq[args.n_past:])\n",
    "        psnr_list.append(psnr)\n",
    "        \n",
    "    ave_psnr = np.mean(np.concatenate(psnr_list))\n",
    "\n",
    "    print(f'ave_psnr = {ave_psnr}')\n",
    "    \n",
    "    try:\n",
    "        test_seq, test_cond = next(test_iterator)\n",
    "    except StopIteration:\n",
    "        test_iterator = iter(test_loader)\n",
    "        test_seq, test_cond = next(test_iterator)\n",
    "\n",
    "    epoch = 600\n",
    "    test_seq = test_seq.transpose(0, 1).to(device)\n",
    "    test_cond = test_cond.transpose(0, 1).to(device)\n",
    "    plot_pred(test_seq, test_cond, modules, epoch, args)\n",
    "    plot_rec(test_seq, test_cond, modules, epoch, args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
